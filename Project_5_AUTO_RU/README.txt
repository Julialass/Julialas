Проект [SF-DST] Car Price prediction
Прогнозирование стоимости автомобиля по характеристикам
https://www.kaggle.com/c/sf-dst-car-price-prediction/overview

В рамках решения по этому проекту представлены 6 ноутбуков и набор файлов к ноутбукам.

 В ПЕРВОМ ноутбуке 
- я изучаю содержимое тестового файла 
- и собираю соответствующие данные с сайта auto.ru в два приёма:

    -- сначала собираю ссылки на предложения в файл collected_links_May_10;
    
    -- а потом считываю информацию с каждого предложения по ссылке и сохраняю в файл.
    
Из-за того, что связь прерывалась, данные собрались в два файла, которые я потом соединяю в следующем ноутбуке: 
train_p5_full.csv и train_p5_full_SMW.csv

 Во ВТОРОМ ноутбуке
я соединяю файлы train_p5_full.csv и train_p5_full_SMW.csv с собранными данными по предложениям о продаже машин тех марок, которые есть в тестовом файле, немного ставлю на место информацию, которая попала в неправильное поле из-за того, что предыдущее поле не содержало информации
и сохраняю данные в файл parsed_data.csv для дальнейшей обработки

 В ТРЕТЬЕМ ноутбуке
я привожу данные в тестовом файле и в файле с данными, собранными для обучения, к единому виду:

удаляю дубликаты,
заполняю или удаляю пропущенные значения
оставляю одинаковое количество признаков
Файлы train_df_cleaned.csv и test_df_cleaned.csv готовы для дальнейшей предобработки.

В ЧЕТВЁРТОМ ноутбуке
я провожу предобработку данных для обучения и предсказания:

оцениваю нормальность распределения целевой переменной в сете для обучения и трансформирую их, чтобы ненормальность не мешала обучению;
оцениваю нормальность распределения числовых признаков и трансформирую их;
оцениваю корреляцию числовых признаков между собой и с целевой переменной, схлопываю два скореллированных признака в один;
обрабатываю категориальные признаки
Файлы 'train_df_preprocessed.csv и 'test_df_preprocessed.csv переходят в ледующий ноутбук для обучения моделей и выдачи предсказаний.

В ПЯТОМ ноутбуке были применены четыре модели
Linear Support Vector Regression, полученный результат МAPE 2.23%
Stochastic Gradient Descent, MAPE 1.88%
LightGBM - a gradient boosting model that uses tree-based learning algorithms, MAPE 1.69%
СatBoost, полученный результат МAPE 0.92%
Было проведено сравнение того, как модели оценили вклад признаков в предсказания, визуализация приведена ниже.

Стекинг моделей при помощи StackingRegressor от sklearn (мета-регрессором выбран Random Forest Regressor) показал результат MAPE 1.08%

В ШЕСТОМ ноутбуке
я имплементирую семь моделей:

RandomForestRegressor , показалa метрику MAPE 0.93%;
Linear Support Vector Regression показалa метрику MAPE 2.03%, бэггинг не улучшил модель;
Linear least squares with l2 regularization regression (Ridge) показалa метрику MAPE 1.88%, бэггинг не улучшил модель;
Nearest Neighbors Regression показалa метрику MAPE 1.13%, бэггинг не улучшил модель;
Stochastic Gradient Descent показалa метрику MAPE 1.88%;
LightGBM - a gradient boosting model that uses tree-based learning algorithms показалa метрику MAPE 1.69%;
CatBoost показалa метрику MAPE 0.92%
Показано сравнение, как модели оценили вклад признаков, кроме Nearest Neighbors Regression.

Проведены следующие эксперименты со стекингом:

стекинг всех 7 моделей, с использованием метода out-of-fold, LinearRegressor в качестве мета-модели; MAPE 0.8906
стекинг 3х лучших моделей, с использованием метода out-of-fold, LinearRegressor в качестве мета-модели; MAPE 0.89959
стекинг 3х лучших моделей, с использованием метода out-of-fold, SGDRegressor в качестве мета-модели; MAPE 0.8973
стекинг 3х лучших моделей, с использованием метода out-of-fold, Random Forest Regressor в качестве мета-модели; MAPE 0.9183
стекинг всех 7 моделей, с использованием метода out-of-fold, SGDRegressor с подбором параметров в качестве мета-модели; MAPE 0.883
